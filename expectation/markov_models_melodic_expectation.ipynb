{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eef6769",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MusicalInformatics/miws2024/blob/main/expectation/markov_models_melodic_expectation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5183df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "HOME_DIR = \".\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Issues on Colab with newer versions of MIDO\n",
    "    !pip install mido==1.2.10\n",
    "    !pip install partitura\n",
    "    !pip install python-hiddenmarkov\n",
    "    \n",
    "    !git clone --recurse-submodules https://github.com/MusicalInformatics/miws2024\n",
    "    import sys\n",
    "    sys.path.insert(0, \"/content/miws2024/expectation/\")\n",
    "    HOME_DIR = \"/content/miws2024/expectation/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e35620ff",
   "metadata": {},
   "source": [
    "# Melodic Expectation with Markov Models\n",
    "\n",
    "In this notebook we will look at Markov Chains for modeling musical expectation.\n",
    "\n",
    "## Quick Recap of Probability\n",
    "\n",
    "* Probability: measure of the **likelihood** of an event\n",
    "\n",
    "* $0\\leq p(x) \\leq 1$, \n",
    "    * $p(x) = 0$ indicates that the event is very unlikely to occur \n",
    "    * $p(x) = 1$ indicates that the event will most likely occur\n",
    "    \n",
    "* Random variables: $X$ can take values $x$\n",
    "\n",
    "    \n",
    "## Quick Recap: Graph Theory\n",
    "\n",
    "* Graphs: A tuple $\\mathcal{G}=(\\mathbf{X}, \\mathbf{E})$ consisting in a set of nodes $\\mathbf{X} = \\{X_1,\\dots,X_N\\}$ and a set of edges $\\mathbf{E}$ connecting the nodes.\n",
    "\n",
    "* Edges can be *directed* $(X_i \\rightarrow X_j)$ or *undirected* $(X_i - X_j)$. If the nodes of a graph are directed, we call it a *directed Graph*, otherwise is an *undirected graph*\n",
    "* Parent and Children nodes: In directed graphs, if $(X_i \\rightarrow X_j)\\in \\mathbf{E}$ then $X_i$ is a parent of $X_j$ and $X_j$ is a child of $X_i$. \n",
    "    * $\\mathbf{Pa}(X_i)$ is the set of parents of $X_i$\n",
    "    * $\\mathbf{Ch}(X_i)$ is the set of children of $X_i$\n",
    "    \n",
    "Let's consider this graph\n",
    "\n",
    "<div>\n",
    "<img src=\"img/graph_example.png\" width=\"250\"/>\n",
    "</div>\n",
    "\n",
    "* the parents of $X_3$ are $\\mathbf{Pa}(X_3) = \\{X_1, X_2\\}$.\n",
    "* Which are the parents of $X_4$?\n",
    "* Which are the parents of $X_1$?\n",
    "\n",
    "\n",
    "## Quick Recap: Probabilistic Graphical Models\n",
    "\n",
    "* Probabilistic graphical models (PGMs) provide a way to visualize the structure of a probabilisitc model\n",
    "\n",
    "* Easy and elegant way to represent conditional independence properties\n",
    "\n",
    "* **Bayesian Networks**: Nodes in a graph represent *random variable* and edges specify conditional independence properties:\n",
    "\n",
    "$$p(X_1, \\dots, X_N) = \\prod_{i=1}^{N} p(X_i \\mid \\mathbf{Pa}(X_i))$$\n",
    "\n",
    "\n",
    "For the example above\n",
    "\n",
    "$$p(X_1, X_2, X_3, X_4, X_5, X_6) = p(X_1) p(X_2) p(X_3\\mid X_1, X_2) p(X_4 \\mid X_3) p(X_5 \\mid X_3) p(X_6 \\mid X_3)$$\n",
    "\n",
    "## Markov Models\n",
    "\n",
    "### Independent Observations\n",
    "* The simplest way of modeling a sequence of observations is to treat them as independent\n",
    "\n",
    "<div>\n",
    "<img src=\"img/independent_markov.png\" width=\"250\"/>\n",
    "</div>\n",
    "\n",
    "$$p(\\mathbf{x}_1\\dots, \\mathbf{x}_N) = \\prod_{n=1}^{N} p(\\mathbf{x}_i)$$\n",
    "\n",
    "but this is a poor assumption for inherently sequential data (like music!)\n",
    "\n",
    "### First order Markov Chains\n",
    "\n",
    "The conditional distribution of each variable is independent of all previous observations except for the *most recent*\n",
    "\n",
    "<div>\n",
    "<img src=\"img/first_order_markov.png\" width=\"250\"/>\n",
    "</div>\n",
    "\n",
    "$$p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N) = p(\\mathbf{x}_1)\\prod_{n=2}^{N}p(\\mathbf{x}_nÂ \\mid \\mathbf{x}_{n-1})$$\n",
    "\n",
    "\n",
    "\n",
    "## Information theoretic measures of musical expectation\n",
    "\n",
    "* Information Content: Unexpectedness of a musical event\n",
    "\n",
    "$$\\text{IC}(\\mathbf{x}_n\\mid \\mathbf{x}_{n-1}, \\dots) = -\\log_2 p(\\mathbf{x}_n \\mid \\mathbf{x}_{n-1}, \\dots )$$\n",
    "\n",
    "* Entropy: How uncertain is a musical event\n",
    "\n",
    "$$\\text{H}(\\mathbf{x}_{n-1:1})= \\sum_{i \\in \\mathbf{A}} p(\\mathbf{x}_i \\mid \\mathbf{x}_{n-1}, \\dots) \\text{IC}(\\mathbf{x}_i\\mid \\mathbf{x}_{n-1}, \\dots)$$\n",
    "\n",
    "where $\\mathbf{A}$ is the set of possible states that $\\mathbf{x}$ can take.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30ea261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Uncomment this line if the kernel keeps crashing\n",
    "# See https://stackoverflow.com/a/53014308\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "import numpy as np\n",
    "import partitura as pt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea836bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "\n",
    "# To filter out short melodies by the minimum number of notes that a sequence should have\n",
    "\n",
    "min_seq_len = 10\n",
    "sequences = load_data(min_seq_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a598ae3b",
   "metadata": {},
   "source": [
    "## Tasks 1: Data loading & preparation\n",
    "1. Check out the content of the variable \"sequences\", if unclear have a look at the loading function.\n",
    "\n",
    "2. Which musical texture do these sequences exhibit? (https://en.wikipedia.org/wiki/Texture_(music))\n",
    "\n",
    "3. Write a function to derive sequences of pitches from this data.\n",
    "\n",
    "4. Write a function to derive sequences of durations from this data. Modify this to compute inter onset intervals (IOIs; the time between two consecutive onsets). Can you encode rests as well by comparing duration with IOI? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a17d83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decide which features to use!\n",
    "feature_names = \"pitch\"\n",
    "features = []\n",
    "for seq in sequences:\n",
    "\n",
    "    if feature_names == \"pitch\":\n",
    "        # pitch\n",
    "        features.append(seq[\"pitch\"])\n",
    "    elif feature_names == \"pitch_class\":\n",
    "        # pitch class\n",
    "        features.append(np.mod(seq[\"pitch\"], 12))\n",
    "    elif feature_names == \"pitch_duration\":\n",
    "        # pitch and duration\n",
    "        features.append(np.column_stack([seq[\"pitch\"], seq[\"duration_sec\"]]))\n",
    "    elif feature_names == \"pitch_ioi\":\n",
    "        # TODO: Implement computing IOIs!\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef7fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import product\n",
    "from utils import get_indices_cartesian_product, find_nearest, QUANTIZED_DURATIONS\n",
    "\n",
    "\n",
    "class Encoder(object):\n",
    "    \"\"\"\n",
    "    A hand-crafted encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        self.classes_ = None\n",
    "        self.dim_encoders: List[LabelEncoder] = []\n",
    "\n",
    "    def fit(self, y: np.ndarray) -> None:\n",
    "\n",
    "        if self.feature_names in (\"pitch\", \"pitch_class\"):\n",
    "            pitch_dim_enc = LabelEncoder()\n",
    "\n",
    "            pitch_dim_enc.fit(y)\n",
    "\n",
    "            self.dim_encoders = [pitch_dim_enc]\n",
    "\n",
    "            self.classes_ = pitch_dim_enc.classes_\n",
    "\n",
    "        else:\n",
    "            # Assume first column is pitch and second is time related\n",
    "            pitch_dim_enc = LabelEncoder()\n",
    "            pitch_dim_enc.fit(y[:, 0])\n",
    "\n",
    "            time_dim_enc = LabelEncoder()\n",
    "\n",
    "            # MIDIs were generated at 100bpm\n",
    "            quantized_time_in_beats = find_nearest(\n",
    "                QUANTIZED_DURATIONS, np.round(y[:, 1] * 100 / 60, 3)\n",
    "            )\n",
    "\n",
    "            time_dim_enc.fit(quantized_time_in_beats)\n",
    "\n",
    "            self.dim_encoders = [pitch_dim_enc, time_dim_enc]\n",
    "\n",
    "            self.classes_ = np.array(\n",
    "                list(product(pitch_dim_enc.classes_, time_dim_enc.classes_))\n",
    "            )\n",
    "\n",
    "    def transform(self, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if self.feature_names in (\"pitch\", \"pitch_class\"):\n",
    "\n",
    "            return self.dim_encoders[0].transform(y)\n",
    "\n",
    "        else:\n",
    "\n",
    "            pitch_encs = self.dim_encoders[0].transform(y[:, 0])\n",
    "            time_encs = self.dim_encoders[1].transform(\n",
    "                find_nearest(QUANTIZED_DURATIONS, np.round(y[:, 1] * 100 / 60, 3))\n",
    "            )\n",
    "\n",
    "            elem = np.column_stack([pitch_encs, time_encs])\n",
    "\n",
    "            print(elem)\n",
    "\n",
    "            return get_indices_cartesian_product(elem, self.classes_)\n",
    "\n",
    "    def inverse_transform(self, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if self.feature_names in (\"pitch\", \"pitch_class\"):\n",
    "\n",
    "            return self.dim_encoders[0].inverse_transform(y)\n",
    "\n",
    "        else:\n",
    "\n",
    "            idxs = self.classes_[y.astype(int)]\n",
    "\n",
    "            pitch_dim = self.dim_encoders[0].inverse_transform(idxs[:, 0])\n",
    "\n",
    "            dur_quant = self.dim_encoders[1].inverse_transform(\n",
    "                find_nearest(QUANTIZED_DURATIONS, np.round(idxs[:, 1] * 100 / 60, 3))\n",
    "            )\n",
    "\n",
    "            # Transform duration in seconds\n",
    "            dur_dim = dur_quant * 60 / 100\n",
    "\n",
    "            return np.column_stack([pitch_dim, dur_dim])\n",
    "\n",
    "    def encode(self, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        return self.transform(y)\n",
    "\n",
    "    def decode(self, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        decoded_labels = self.inverse_transform(y)\n",
    "\n",
    "        if self.feature_names == \"pitch\":\n",
    "\n",
    "            note_array = np.zeros(\n",
    "                len(decoded_labels),\n",
    "                dtype=[\n",
    "                    (\"pitch\", int),\n",
    "                    (\"duration_sec\", float),\n",
    "                    (\"onset_sec\", float),\n",
    "                    (\"velocity\", int),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            note_array[\"pitch\"] = decoded_labels\n",
    "\n",
    "            note_array[\"onset_sec\"] = np.arange(len(decoded_labels)) * 0.5\n",
    "\n",
    "            note_array[\"duration_sec\"] = 0.5\n",
    "\n",
    "            note_array[\"velocity\"] = 64\n",
    "\n",
    "        elif self.feature_names == \"pitch_class\":\n",
    "            note_array = np.zeros(\n",
    "                len(decoded_labels),\n",
    "                dtype=[\n",
    "                    (\"pitch\", int),\n",
    "                    (\"duration_sec\", float),\n",
    "                    (\"onset_sec\", float),\n",
    "                    (\"velocity\", int),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # All notes around Middle C\n",
    "            note_array[\"pitch\"] = decoded_labels + 60\n",
    "\n",
    "            note_array[\"onset_sec\"] = np.arange(len(decoded_labels)) * 0.5\n",
    "\n",
    "            note_array[\"duration_sec\"] = 0.5\n",
    "\n",
    "            note_array[\"velocity\"] = 64\n",
    "\n",
    "        elif self.feature_names == \"pitch_duration\":\n",
    "            pass\n",
    "\n",
    "        elif self.feature_names == \"pitch_ioi\":\n",
    "            pass\n",
    "\n",
    "        return note_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIZED_DURATIONS[find_nearest(QUANTIZED_DURATIONS, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467b29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(feature_names)\n",
    "\n",
    "if feature_names in (\"pitch\", \"pitch_class\"):\n",
    "    # enc = LabelEncoder()\n",
    "    enc.fit(np.hstack(features))\n",
    "elif feature_names in (\"pitch_duration\"):\n",
    "    # enc = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    enc.fit(np.vstack(features))\n",
    "\n",
    "encoded_sequences = [enc.transform(seq) for seq in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc193514",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa7a8b9b",
   "metadata": {},
   "source": [
    "## Tasks 2: Data exploration:\n",
    "\n",
    "1. Compute and draw a histogram of pitches. Modify this to show pitch classes!\n",
    "\n",
    "2. Compute and draw a histogram of IOIs. The input MIDI files are deadpan, i.e. the IOIs in seconds correspond to the notated duration exactly. Look through the IOIs and make an educated guess for some smallest float time unit that could serve as integer smallest time division. Encode the IOIs as multiples of this smallest integer. Which multiples make musical sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ede8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "alphabet_size = len(enc.classes_)\n",
    "alphabet = enc.classes_\n",
    "print(f\"Number of sequences: {len(sequences)}\")\n",
    "print(f\"Unique elements {alphabet_size}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    np.hstack(encoded_sequences),\n",
    "    bins=alphabet_size,\n",
    "    range=(0, alphabet_size),\n",
    "    color=\"firebrick\",\n",
    ")\n",
    "ax.set_xticks(np.arange(alphabet_size) + 0.5)\n",
    "# ax.set_xticklabels(alphabet)\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a674b16f",
   "metadata": {},
   "source": [
    "## Tasks 3: A Markov Chain\n",
    "\n",
    "1. Choose a data type to model: pitch, pitch class, IOIs, or durations (including or without an encoding for rests). Concatenate all the sequences into one long data sequence.\n",
    "\n",
    "2. You have now a sequence **X** of symbols from an alphabet **A** (set of possible symbols of your chosen data type):\n",
    "\n",
    "$$ \\mathbf{X} = \\{\\mathbf{x_0}, \\dots, \\mathbf{x_n} \\mid \\mathbf{x}_{i} \\in  \\mathbf{A} \\forall i \\in 0, \\dots, n \\}$$\n",
    "\n",
    "Compute the empirical conditional probability of seeing any symbol after just having seen any other:\n",
    "\n",
    "$$ p(\\mathbf{x_i}\\mid \\mathbf{x_{i-1}}) $$\n",
    "\n",
    "What is the dimensionality of this probability  given $\\lvert A \\rvert = d $?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5368b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_fom(sequences, alphabet_size):\n",
    "    probs = np.zeros((alphabet_size, alphabet_size)) + 1e-6\n",
    "    for seq in sequences:\n",
    "        for p1, p2 in zip(seq[:-1], seq[1:]):\n",
    "            probs[p1, p2] += 1\n",
    "    probsum = np.sum(probs, axis=1)\n",
    "    normalized_distribution = (probs.T / probsum).T\n",
    "    return normalized_distribution\n",
    "\n",
    "\n",
    "transition_probabilities = maximum_likelihood_fom(encoded_sequences, alphabet_size)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "a = ax.matshow(\n",
    "    transition_probabilities,\n",
    "    aspect=\"equal\",\n",
    "    cmap=\"BuPu\",\n",
    ")\n",
    "ax.set_xticks(range(alphabet_size))\n",
    "# ax.set_xticklabels(enc.classes_)\n",
    "ax.set_yticks(range(alphabet_size))\n",
    "# ax.set_yticklabels(enc.classes_)\n",
    "\n",
    "plt.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e9eaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def probability_of_sequence(\n",
    "    sequence,\n",
    "    transition_probs=transition_probabilities,\n",
    "    alphabet_size=alphabet_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    p(x_1,...,x_n)\n",
    "    \"\"\"\n",
    "    p_0 = 1 / alphabet_size\n",
    "    transitions = np.prod(\n",
    "        [transition_probs[i, j] for i, j in zip(sequence[1:], sequence[:-1])]\n",
    "    )\n",
    "    prob = p_0 * transitions\n",
    "    return prob\n",
    "\n",
    "\n",
    "def information_content_fom(\n",
    "    sequence,\n",
    "    transition_probs=transition_probabilities,\n",
    "    alphabet_size=alphabet_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    For first order Markov models\n",
    "\n",
    "    IC(x_n|x_{n-1},...,x_1) = IC(x_n|x_{n-1}) = - log2(p(x_n | x_{n-1}))\n",
    "    \"\"\"\n",
    "    ic = -np.log2(transition_probs[sequence[-1], sequence[-2]])\n",
    "    return ic\n",
    "\n",
    "\n",
    "def entropy_fom(\n",
    "    sequence,\n",
    "    alphabet=alphabet,\n",
    "    transition_probs=transition_probabilities,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entropy for first order Markov model\n",
    "    \"\"\"\n",
    "    entropy_components = []\n",
    "    for al in alphabet:\n",
    "        in_seq = np.zeros_like(sequence)\n",
    "        in_seq[:-1] = sequence[:-1]\n",
    "        in_seq[-1] = al\n",
    "\n",
    "        ic = information_content_fom(\n",
    "            in_seq, transition_probs, alphabet_size=len(alphabet)\n",
    "        )\n",
    "        prob = transition_probs[al, sequence[-2]]\n",
    "\n",
    "        entropy_components.append(ic * prob)\n",
    "    entropy = np.sum(entropy_components)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d44c602",
   "metadata": {},
   "source": [
    "## Tasks 4: Markov Chain Generation\n",
    "\n",
    "1. By computing the probability $ \\mathbb{P}(\\mathbf{x_i}\\mid \\mathbf{x_{i-1}}) $ in task 3 you have fully specified a discrete-time finite state space Markov Chain model (https://en.wikipedia.org/wiki/Discrete-time_Markov_chain)! Given an initial symbol \"s_0\", you can generate the subsequent symbols by sampling from the conditional probability distribution\n",
    "\n",
    "$$ p(\\mathbf{x_i}\\mid \\mathbf{x_{i-1}} = \\mathbf{s_{0}}) $$\n",
    "\n",
    "Write a function that samples from a finite state space given an input probability distribution.\n",
    "\n",
    "2. Use the previously defined function and the Markov Chain to write a sequence generator based on an initial symbol.\n",
    "\n",
    "3. Start several \"walkers\", i.e. sampled/generated sequences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150bcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from partitura.utils.synth import synthesize, SAMPLE_RATE\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "def sample(distribution):\n",
    "    cs = distribution.cumsum()\n",
    "    samp = np.random.rand(1)\n",
    "    return list(samp < cs).index(True)\n",
    "\n",
    "\n",
    "def generate(start=0, length=100):\n",
    "    melody = [start]\n",
    "    for k in range(length - 1):\n",
    "        melody.append(sample(transition_probabilities[melody[-1], :]))\n",
    "    return np.array(melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_generated_sequence(generated_sequence):\n",
    "\n",
    "    note_array = enc.decode(generated_sequence)\n",
    "\n",
    "    signal = synthesize(\n",
    "        note_array,\n",
    "        harmonic_dist=3,  # \"shepard\",\n",
    "    )\n",
    "    ipd.display(ipd.Audio(data=signal, rate=SAMPLE_RATE, normalize=False))\n",
    "\n",
    "    return note_array\n",
    "\n",
    "\n",
    "n_notes = 100\n",
    "generated_sequence = generate(length=n_notes)\n",
    "print(generated_sequence)\n",
    "note_array = synthesize_generated_sequence(generated_sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbe6b324",
   "metadata": {},
   "source": [
    "## Tasks 5: n-gram Context Model:\n",
    "\n",
    "1. The Markov Chains used until now have only very limited memory. In fact, they only ever know the last played pitch or duration. Longer memory models can be created by using the conditional probability of any new symbol based on an n-gram context of the symbol (https://en.wikipedia.org/wiki/N-gram):\n",
    "$$ p(\\mathbf{x_i}\\mid \\mathbf{x_{i-1}}, \\dots, \\mathbf{x_{i-n}}) $$\n",
    "\n",
    "This probability will generally not look like a matrix anymore, but we can easily encode it as a dictionary. Write a function that creates a 3-gram context model from the data sequence **X**!\n",
    "\n",
    "2. The longer the context, the more data we need to get meaningful or even existing samples for all contexts (note that the number of different contexts grows exponentially with context length). What could we do to approximate the distribution for unseen contexts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d9e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "\n",
    "def create_context_model(sequences, n, n_states=alphabet_size):\n",
    "    a_priori_probability = np.ones(n_states) / n_states\n",
    "    context_model = defaultdict(lambda: copy.copy(a_priori_probability))\n",
    "    for sequence in sequences:\n",
    "        for idx in range(len(sequence) - n):\n",
    "            local_string = \"\"\n",
    "            for p in sequence[idx : idx + n]:\n",
    "                local_string += str(p)\n",
    "            context_model[local_string][sequence[idx + n]] += 1\n",
    "\n",
    "    for key in context_model.keys():\n",
    "        prob_dist = context_model[key]\n",
    "        context_model[key] = prob_dist / prob_dist.sum()\n",
    "\n",
    "    return context_model\n",
    "\n",
    "\n",
    "cm = create_context_model(encoded_sequences, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_context_model(start=[0, 0, 0], length=100, context_model=cm):\n",
    "    melody = start\n",
    "    for k in range(length):\n",
    "        key = \"\"\n",
    "        for p in melody[-len(start) :]:\n",
    "            key += str(p)\n",
    "        \n",
    "        melody.append(sample(context_model[key]))\n",
    "    return np.array(melody)\n",
    "\n",
    "\n",
    "start = list(enc.transform([60, 62, 64]))\n",
    "generated_sequence = generate_with_context_model(start=start)\n",
    "\n",
    "note_array = synthesize_generated_sequence(generated_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miws24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
