{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composer Identification with CNNs\n",
    "\n",
    "In this notebook we are going to explore composer identification using convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start importing stuff!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import partitura as pt\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from partitura.utils.music import compute_pianoroll\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from classification_utils import (\n",
    "    COMPOSER_CLASSES,\n",
    "    CLASSES_COMPOSER,\n",
    "    encode_composer,\n",
    "    segment_array,\n",
    "    predict_piece,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"partitura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FN = \"composer_classification_training.csv\"\n",
    "data = pd.read_csv(DATASET_FN)\n",
    "\n",
    "# Let's see how the data looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scores in MusicXML format, and for each score we have the composer.\n",
    "\n",
    "Let's look now at the distribution of the composers. Do you notice anything in particular about this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of each unique category\n",
    "value_counts = data[\"Composer\"].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.bar(\n",
    "    value_counts.index,\n",
    "    value_counts.values,\n",
    "    color=\"firebrick\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"Composer\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Frequency of Composers\")\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COMPOSER_CLASSES)\n",
    "\n",
    "composer_indices = encode_composer(data[\"Composer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now load the scores. For this tutorial we are going to use piano rolls as a low-level representation of the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this path with the location where you downloaded the files\n",
    "PIANO_ROLL_DIR = \"piano_rolls_numpy\"\n",
    "# Replace this path with the location where you downloaded the files\n",
    "MUSICXML_DIR = \"scores_composer_identification\"\n",
    "\n",
    "pianorolls = []\n",
    "\n",
    "# Divisions per beat\n",
    "time_div = 10\n",
    "\n",
    "for sfn in data[\"Score\"]:\n",
    "\n",
    "    pr_fn = os.path.join(PIANO_ROLL_DIR, f\"{sfn}.npz\")\n",
    "\n",
    "    if not os.path.exists(pr_fn):\n",
    "        # Load scores\n",
    "        score = pt.load_musicxml(os.path.join(MUSICXML_DIR, sfn))\n",
    "        # Compute piano roll\n",
    "        pr = compute_pianoroll(\n",
    "            score,\n",
    "            piano_range=True, \n",
    "            time_unit=\"beat\",\n",
    "            time_div=time_div,\n",
    "        ).toarray().T\n",
    "        \n",
    "        # Save piano roll\n",
    "        np.savez_compressed(pr_fn, array=pr)\n",
    "    else:\n",
    "        pr = np.load(pr_fn)[\"array\"]\n",
    "\n",
    "    pianorolls.append(pr)\n",
    "\n",
    "pianorolls = np.array(pianorolls, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a piano roll of this kind of data looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    pianorolls[0].T,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Piano key\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to split by piece (to ensure that segments of pieces appear only in training, testing or validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets with stratified sampling\n",
    "test_size = 0.2\n",
    "pr_train_val, pr_test, ci_train_val, ci_test = train_test_split(\n",
    "    pianorolls,\n",
    "    composer_indices,\n",
    "    test_size=test_size,\n",
    "    stratify=composer_indices,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_size = 0.1\n",
    "pr_train, pr_val, ci_train, ci_val = train_test_split(\n",
    "    pr_train_val,\n",
    "    ci_train_val,\n",
    "    test_size=val_size,\n",
    "    stratify=ci_train_val,\n",
    "    random_state=1942,\n",
    ")\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"X_train shape: {pr_train.shape}, Y_train shape: {ci_train.shape}\")\n",
    "print(f\"X_val shape: {pr_val.shape}, Y_val shape: {ci_val.shape}\")\n",
    "print(f\"X_test shape: {pr_test.shape}, Y_test shape: {ci_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, sharex=True, figsize=(6, 5))\n",
    "\n",
    "unique_classes = np.array(list(COMPOSER_CLASSES.keys()))\n",
    "# unique, counts = np.unique(array, return_counts=True)\n",
    "\n",
    "unique_train, counts_train = np.unique(\n",
    "    ci_train,\n",
    "    return_counts=True,\n",
    ")\n",
    "unique_val, counts_val = np.unique(\n",
    "    ci_val,\n",
    "    return_counts=True,\n",
    ")\n",
    "unique_test, counts_test = np.unique(\n",
    "    ci_test,\n",
    "    return_counts=True,\n",
    ")\n",
    "\n",
    "# Plot the histogram\n",
    "axes[0].bar(unique_train, counts_train, color=\"firebrick\", edgecolor=\"black\")\n",
    "axes[0].set_title(\"Training set\")\n",
    "axes[1].bar(unique_val, counts_val, color=\"firebrick\", edgecolor=\"black\")\n",
    "axes[1].set_title(\"Validation set\")\n",
    "axes[2].bar(unique_test, counts_test, color=\"firebrick\", edgecolor=\"black\")\n",
    "axes[2].set_title(\"Test set\")\n",
    "axes[2].set_xlabel(\"Composer index\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "\n",
    "# Show the plot with tight layout to avoid label overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the segment\n",
    "pr_segment_length = 16 * 10\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for pr, ci in zip(pr_train, ci_train):\n",
    "\n",
    "    segmented_pr = segment_array(\n",
    "        array=pr,\n",
    "        window_length=pr_segment_length,\n",
    "    )\n",
    "    targets = np.ones(len(segmented_pr)) * ci\n",
    "\n",
    "    X_train.append(segmented_pr)\n",
    "    Y_train.append(targets)\n",
    "\n",
    "# Concatenate the arrays\n",
    "X_train = np.concatenate(X_train)\n",
    "Y_train = np.concatenate(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the segment\n",
    "pr_segment_length = 16 * 10\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for pr, ci in zip(pr_val, ci_val):\n",
    "\n",
    "    segmented_pr = segment_array(\n",
    "        array=pr,\n",
    "        window_length=pr_segment_length,\n",
    "    )\n",
    "    targets = np.ones(len(segmented_pr)) * ci\n",
    "\n",
    "    X_val.append(segmented_pr)\n",
    "    Y_val.append(targets)\n",
    "\n",
    "# Concatenate the arrays\n",
    "X_val = np.concatenate(X_val)\n",
    "Y_val = np.concatenate(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training examples\", len(X_train))\n",
    "print(\"Validation examples\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(\n",
    "    1\n",
    ")  # Add channel dimension\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(\n",
    "    1\n",
    ")  # Add channel dimension\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.long)\n",
    "\n",
    "# Hyperparameters\n",
    "n_classes = len(COMPOSER_CLASSES)\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "\n",
    "# Create DataLoader for training and valing sets\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_classes=9, input_height=X_train.shape[1], input_width=X_train.shape[2]\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            1, 32, kernel_size=3, stride=1, padding=1\n",
    "        )  # Output: (batch_size, 32, input_height, input_width)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            32, 64, kernel_size=3, stride=1, padding=1\n",
    "        )  # Output: (batch_size, 64, input_height, input_width)\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size=2, stride=2, padding=0\n",
    "        )  # Halves the spatial dimensions\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Compute the size after conv and pooling layers\n",
    "        self.flattened_size = self._get_flattened_size(input_height, input_width)\n",
    "\n",
    "        # Now, initialize the fully connected layers with the correct input size\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def _get_flattened_size(self, height, width):\n",
    "        # Pass a dummy input through conv and pool layers to get the output size\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, height, width)\n",
    "            x = self.pool(self.relu(self.conv1(x)))\n",
    "            x = self.pool(self.relu(self.conv2(x)))\n",
    "            flattened_size = x.numel()\n",
    "        return flattened_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # After first conv and pool\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # After second conv and pool\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = CNN(n_classes=n_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_val_acc = 0.0  # Initialize best validation accuracy\n",
    "validate_freq = 1  # Set validation frequency (default is 1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=f\"Epoch {epoch+1}/{num_epochs}\",\n",
    "    )\n",
    "    for i, (inputs, labels) in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": running_loss / (i + 1)})\n",
    "\n",
    "    # Perform validation every 'validate_freq' epochs\n",
    "    if (epoch + 1) % validate_freq == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save checkpoint if validation accuracy improves\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model_checkpoint.pth\")\n",
    "            print(\"Model checkpoint saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary from the saved file\n",
    "state_dict = torch.load(\n",
    "    \"best_model_checkpoint.pth\",\n",
    "    map_location=device,\n",
    ")\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def plot_predictions(n=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = next(iter(val_loader))\n",
    "        inputs, labels = inputs[:n].to(device), labels[:n].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        fig, axes = plt.subplots(1, n, figsize=(15, 6))\n",
    "        for i in range(n):\n",
    "            axes[i].imshow(\n",
    "                inputs[i].cpu().squeeze().T,\n",
    "                cmap=\"gray\",\n",
    "                aspect=\"auto\",\n",
    "                interpolation=\"nearest\",\n",
    "            )\n",
    "            axes[i].set_title(f\"True: {labels[i].item()} Pred: {predicted[i].item()}\")\n",
    "            axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = []\n",
    "for pr in pr_test:\n",
    "\n",
    "    pred = predict_piece(\n",
    "        pianoroll=pr,\n",
    "        segment_length=16 * 10,\n",
    "        cnn=model,\n",
    "        device=device,\n",
    "    )\n",
    "    predictions_test.append(pred)\n",
    "\n",
    "predictions_test = np.array(predictions_test)\n",
    "\n",
    "accuracy_test = np.mean(predictions_test == ci_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    predictions=predictions_test,\n",
    "    targets=ci_test,\n",
    "    class_names=list(COMPOSER_CLASSES.keys()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the macro F1 score\n",
    "macro_f1 = f1_score(ci_test, predictions_test, average=\"macro\")\n",
    "micro_f1 = f1_score(ci_test, predictions_test, average=\"micro\")\n",
    "print(f\"Accuracy {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Macro F1 Score: {macro_f1 * 100:.2f}%\")\n",
    "print(f\"Micro F1 Score: {micro_f1 * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miws24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
